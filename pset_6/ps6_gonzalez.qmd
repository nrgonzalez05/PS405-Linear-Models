---
title: "Problem Set 6"
author: "Nicholas R. Gonzalez"
format: pdf
editor: visual
---

# Problem 1 

## Hints 

```{r}
#install.packages("mlmRev")
library(mlmRev)
df <- Hsb82

View(Hsb82)

df$school <- as.factor(df$school)

unique(df$sector)

df$sector <- relevel(factor(df$sector), ref = "Public")

levels(df$sector)



```

### a 

Intercept (13.242)
	•	This represents the expected math achievement score for a public school, non-minority, male student with SES = 0.
	•	Since SES is typically standardized (mean = 0), this is the baseline score.
	
	
	Sector: Catholic vs. Public (2.255, p < 0.05)
	•	Attending a Catholic school is associated with a 2.255-point higher math achievement score than attending a public school, holding other variables constant.
	•	This suggests a positive effect of Catholic schooling.
	
	
	Minority Status (-3.112, p < 0.05)
	•	Being a minority student is associated with a 3.112-point lower math score compared to non-minority students, controlling for school sector, sex, and SES.
	•	This is a significant gap, indicating potential disparities in educational outcomes.
	
	
	Sex: Female (-1.422, p < 0.05)
	•	Female students score 1.422 points lower than male students, holding other factors constant.
	•	This suggests a gender gap in math achievement.
	5.	Socioeconomic Status (SES) (2.364, p < 0.05)
	•	A one-unit increase in SES is associated with a 2.364-point increase in math scores.
	•	SES has a substantial effect, highlighting the strong relationship between socioeconomic background and academic performance
	
	Conclusion
	•	Catholic school students outperform public school students in math.
	•	Minority students have significantly lower math scores, even after controlling for school type, SES, and sex.
	•	Females score lower than males in math, suggesting a gender gap.
	•	SES is strongly positively associated with math achievement.


```{r}
model <- lm(mAch ~ sector + minrty + sx + ses, data = df)

library(modelsummary)

modelsummary(model)

```


### b 

Yes, clustering standard errors is appropriate in this case because students are likely nested within schools, meaning observations are not independent within clusters (schools).


### c

My coefficients stayed the same but my standard errors increased, by about 100%. This is because without clustering, standard errors assume each student is independent. So clustering would adjust for intra-school correlation. 


```{r}
library(estimatr)

df$school_yr <- as.numeric(factor(df$school))

model_clustered <- lm_robust(mAch ~ sector + minrty + sx + ses, 
                             data = df, 
                             clusters = school_yr)  

modelsummary(model_clustered)
```



### d

All results are within a hundreth of each other. 

```{r}
#install.packages('sandwich')
#install.packages('lmtest')
library(sandwich)
library(lmtest)

model <- lm(mAch ~ sector + minrty + sx + ses, data = df)
summary(model)

vcov_clustered <- vcovCL(model, cluster = ~school_id)

coeftest(model, vcov = vcov_clustered) 

```

### e 

The standard errors go down, there is more data.

```{r}
library(multiwayvcov)
library(lmtest)

model <- lm(mAch ~ sector + minrty + sx + ses, data = df)
summary(model)

set.seed(123) 

vcov_boot <- cluster.boot(model, cluster = df$school_id, R = 1000, parallel = TRUE)

coeftest(model, vcov = vcov_boot)

```


# Problem 2

### a 

The ratio of standard errors between the clustered and non-clustered models is influenced by the structure of the data and how clustering affects the variance estimation. 


```{r}
pset6data <- function(m, n){ 
  beta0 <- 0.3
  beta1 <- 0.8
  cluster.id <- sort(rep(1:m,n))
  d <- as.data.frame(cluster.id)
  d$X <- c()
  d$Y <- c()
  d$v <- c()
  d$epsilon <- c()
  for(i in 1:m){ # For each group
    v <- rnorm(1, 0, 0.5) # Group component in U
    mu <- rnorm(1, 0, 0.5) # Group component in X
    for(j in 1:n){ # For each observation in the group
      d$v[(i-1)*n+j] <- v
      d$X[(i-1)*n+j] <- rnorm(1, 0, 1) + mu
      d$epsilon[(i-1)*n+j] <- rnorm(1, 0, 0.5) # Individual component in U
      d$Y[(i-1)*n+j] <- beta0 + beta1*d$X[(i-1)*n+j] + d$v[(i-1)*n+j] + d$epsilon[(i-1)*n+j]
    }
  }
  return(d)
}
```


```{r}

set.seed(123)

scenario_one <- pset6data(10, 500)

model_one <- lm(Y ~ X, data = scenario_one)

model_one_cluster <- lm_robust(Y ~ X, data = scenario_one, clusters = scenario_one$cluster.id)

scenario_two <- pset6data(50, 100)

model_two <- lm(Y ~ X, data = scenario_two)

model_two_cluster <- lm_robust(Y ~ X, data = scenario_two, clusters = scenario_one$cluster.id)

scenario_three_cluster <- pset6data(100, 50)

model_three <- lm(Y ~ X, data = scenario_three)

model_three_cluster <- lm_robust(Y ~ X, data = scenario_three, clusters = scenario_one$cluster.id)

scenario_four <- pset6data(500, 10)

model_four <- lm(Y ~ X, data = scenario_four)

model_four_cluster <- lm_robust(Y ~ X, data = scenario_four, clusters = scenario_one$cluster.id)

# cant do model summary with lm_robust?

summary(model_one)
summary(model_one_cluster)
summary(model_two)
summary(model_two_cluster)
summary(model_three)
summary(model_three_cluster)
summary(model_four)
summary(model_four_cluster)






```

### b

**Scenario 1:**

•	The coefficient remains the same in both models.
	•	The standard error in the non-clustered model is much smaller (0.0085) than in the clustered model (0.0311). This is expected because clustering accounts for intra-cluster correlation, which leads to larger standard errors to reflect the added uncertainty in the estimates due to clustering.

**Scenario 2:**

The coefficient is unchanged.
	•	The standard error in the non-clustered model is smaller (0.0086) than in the clustered model (0.0379). Again, this is due to clustering accounting for additional variation within clusters, leading to more conservative (larger) standard errors.

**Scenario 3:**

	The coefficient remains identical.
	•	The standard error is larger in the clustered model (0.0137) compared to the non-clustered model (0.0089). Clustering adds more uncertainty by accounting for intra-cluster correlations.
	

**Scenario 4:**

The coefficient is unchanged.
	•	The standard error is larger in the clustered model (0.0139) compared to the non-clustered model (0.0088), again reflecting the intra-cluster correlation that the clustered standard errors adjust for.
	

Coefficient estimates are the same between the non-clustered and clustered models.
	•	Standard errors are larger in the clustered models. This is because clustering corrects for the possibility that observations within the same cluster may not be independent, leading to more conservative (larger) estimates of the standard errors.
	
		This is because we have too many clusters, comapred to the amount of units we have, this causes us to have increased SE.




